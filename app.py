import streamlit as st
import google.generativeai as genai

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(page_title="My Private Gemini", layout="centered")

# ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§ãƒ¢ãƒ‡ãƒ«é¸æŠï¼ˆ3.0 Proãªã©ã‚’æŒ‡å®šå¯èƒ½ã«ï¼‰
st.sidebar.title("è¨­å®š")
model_name = st.sidebar.selectbox(
    "ãƒ¢ãƒ‡ãƒ«é¸æŠ",
    ["gemini-1.5-pro", "gemini-1.5-flash", "gemini-3-pro-preview"], # ä½¿ã„ãŸã„ãƒ¢ãƒ‡ãƒ«åã‚’ã“ã“ã«è¿½è¨˜
    index=2 # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚’Gemini 3.0ã«
)

# APIã‚­ãƒ¼ã®èª­ã¿è¾¼ã¿ï¼ˆè¨­å®šç”»é¢ã‹ã‚‰èª­ã¿è¾¼ã‚€å®‰å…¨ãªæ–¹æ³•ï¼‰
if "GOOGLE_API_KEY" in st.secrets:
    api_key = st.secrets["GOOGLE_API_KEY"]
else:
    st.error("APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚Streamlitã®Secretsã«è¨­å®šã—ã¦ãã ã•ã„ã€‚")
    st.stop()

genai.configure(api_key=api_key)

# ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®åˆæœŸåŒ–
if "messages" not in st.session_state:
    st.session_state.messages = []

# ã‚¿ã‚¤ãƒˆãƒ«è¡¨ç¤º
st.title(f"ğŸ¤– Private Gemini ({model_name})")
st.caption("ä¼šç¤¾PCé–²è¦§ç”¨ï¼šæ©Ÿå¯†æƒ…å ±ã¯å…¥åŠ›ç¦æ­¢")

# éå»ã®å±¥æ­´ã‚’è¡¨ç¤º
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# å…¥åŠ›ãƒ•ã‚©ãƒ¼ãƒ 
if prompt := st.chat_input("ã“ã“ã«ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å…¥åŠ›..."):
    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…¥åŠ›ã‚’è¡¨ç¤º
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    # AIã®è¿”ç­”ã‚’ç”Ÿæˆ
    with st.chat_message("assistant"):
        try:
            # ãƒ¢ãƒ‡ãƒ«ã®æº–å‚™
            model = genai.GenerativeModel(model_name)
            
            # å±¥æ­´ã‚’å«ã‚ã¦é€ä¿¡ï¼ˆæ–‡è„ˆã‚’ç†è§£ã•ã›ã‚‹ï¼‰
            chat_history = [
                {"role": m["role"], "parts": [m["content"]]} 
                for m in st.session_state.messages[:-1] # ä»Šå›ã®å…¥åŠ›ã‚’é™¤ãéå»ãƒ­ã‚°
            ]
            chat = model.start_chat(history=chat_history)
            
            # ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°è¡¨ç¤ºï¼ˆæ–‡å­—ãŒãƒ‘ãƒ©ãƒ‘ãƒ©å‡ºã‚‹ã‚„ã¤ï¼‰
            response_container = st.empty()
            full_response = ""
            response = chat.send_message(prompt, stream=True)
            
            for chunk in response:
                if chunk.text:
                    full_response += chunk.text
                    response_container.markdown(full_response)
            
            # å±¥æ­´ã«ä¿å­˜
            st.session_state.messages.append({"role": "model", "content": full_response})

        except Exception as e:
            st.error(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
